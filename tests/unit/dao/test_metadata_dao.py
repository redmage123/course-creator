"""
Metadata DAO Unit Tests

BUSINESS CONTEXT:
Comprehensive tests for Metadata Data Access Object ensuring all metadata management,
fuzzy search, tag-based queries, and analytics operations work correctly. The metadata
DAO is critical for content discovery, search functionality, and file upload/download
tracking across the platform. It powers the intelligent search features that help
students and instructors find relevant educational content.

TECHNICAL IMPLEMENTATION:
- Tests all 18 DAO methods covering metadata operations
- Validates full-text search with PostgreSQL tsvector
- Tests fuzzy search with pg_trgm extension (typo tolerance)
- Validates tag-based queries with array operators
- Tests materialized view analytics for file tracking
- Ensures metadata versioning and JSONB operations

TDD APPROACH:
These tests validate that the DAO layer correctly:
- Creates and manages metadata with JSONB storage
- Performs full-text search with relevance ranking
- Handles fuzzy search with similarity thresholds
- Executes tag-based queries with AND logic
- Provides upload/download analytics from materialized views
- Maintains data integrity across metadata operations
"""

import pytest
import asyncpg
from datetime import datetime, timedelta
from uuid import uuid4, UUID
import sys
from pathlib import Path
import json

# Add metadata-service to path
metadata_path = Path(__file__).parent.parent.parent.parent / 'services' / 'metadata-service'
sys.path.insert(0, str(metadata_path))

from data_access.metadata_dao import MetadataDAO
from metadata_service.domain.entities.metadata import Metadata
from data_access.metadata_dao import (
    MetadataDAOError,
    MetadataAlreadyExistsError,
    MetadataNotFoundError
)


class TestMetadataDAOCreate:
    """
    Test Suite: Metadata Creation Operations

    BUSINESS REQUIREMENT:
    System must create metadata records with JSONB storage for flexible
    schema evolution and rich entity description capabilities.
    """

    @pytest.mark.asyncio
    async def test_create_metadata_with_full_fields(self, db_transaction):
        """
        TEST: Create metadata with all fields populated

        BUSINESS REQUIREMENT:
        Metadata must support comprehensive entity descriptions including
        title, description, tags, keywords, and custom metadata properties.

        VALIDATES:
        - Metadata record created in entity_metadata table
        - JSONB metadata stored correctly
        - Tags array stored and retrievable
        - Timestamps auto-generated
        - Search vector auto-generated by trigger
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        entity_id = uuid4()
        creator_id = uuid4()

        metadata = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='Introduction to Python Programming',
            description='Comprehensive Python course covering basics to advanced topics',
            tags=['python', 'programming', 'beginner'],
            keywords=['coding', 'software', 'development'],
            metadata={
                'educational': {
                    'difficulty': 'beginner',
                    'duration_hours': 40,
                    'topics': ['variables', 'functions', 'classes']
                },
                'quality': {
                    'rating': 4.5,
                    'reviews': 150
                }
            },
            created_by=creator_id,
            updated_by=creator_id
        )

        # Execute: Create metadata
        result = await dao.create(metadata, connection=db_transaction)

        # Verify: Metadata created
        assert result.id is not None
        assert result.entity_id == entity_id
        assert result.entity_type == 'course'
        assert result.title == 'Introduction to Python Programming'
        assert 'python' in result.tags
        assert 'programming' in result.tags

        # Verify: Database record exists
        db_metadata = await db_transaction.fetchrow(
            "SELECT * FROM entity_metadata WHERE entity_id = $1",
            entity_id
        )
        assert db_metadata is not None
        assert db_metadata['title'] == metadata.title
        assert 'python' in db_metadata['tags']

    @pytest.mark.asyncio
    async def test_create_metadata_duplicate_entity_fails(self, db_transaction):
        """
        TEST: Creating duplicate metadata for same entity fails

        BUSINESS REQUIREMENT:
        Each entity can only have one metadata record to maintain
        consistency and avoid data fragmentation.

        VALIDATES:
        - Unique constraint on (entity_id, entity_type)
        - MetadataAlreadyExistsError raised
        - Original metadata unchanged
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        entity_id = uuid4()

        # Create first metadata
        metadata1 = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='First Metadata'
        )
        await dao.create(metadata1, connection=db_transaction)

        # Attempt duplicate creation
        metadata2 = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='Duplicate Metadata'
        )

        with pytest.raises(MetadataAlreadyExistsError) as exc_info:
            await dao.create(metadata2, connection=db_transaction)

        assert 'already exists' in str(exc_info.value).lower()
        assert str(entity_id) in str(exc_info.value)


class TestMetadataDAORetrieve:
    """
    Test Suite: Metadata Retrieval Operations

    BUSINESS REQUIREMENT:
    System must efficiently retrieve metadata by ID, entity reference,
    and entity type for content discovery and display.
    """

    @pytest.mark.asyncio
    async def test_get_metadata_by_id(self, db_transaction):
        """
        TEST: Retrieve metadata by primary key ID

        BUSINESS REQUIREMENT:
        Fast metadata lookup by ID for direct entity access

        VALIDATES:
        - Metadata retrieved by UUID
        - All fields deserialized correctly
        - JSONB metadata parsed to dict
        - Tags array converted to list
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        entity_id = uuid4()
        metadata = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='Test Course',
            tags=['test', 'course'],
            metadata={'key': 'value'}
        )

        created = await dao.create(metadata, connection=db_transaction)

        # Execute: Retrieve by ID
        retrieved = await dao.get_by_id(created.id)

        # Verify: Metadata retrieved correctly
        assert retrieved is not None
        assert retrieved.id == created.id
        assert retrieved.entity_id == entity_id
        assert retrieved.title == 'Test Course'
        assert 'test' in retrieved.tags
        assert retrieved.metadata['key'] == 'value'

    @pytest.mark.asyncio
    async def test_get_metadata_by_entity(self, db_transaction):
        """
        TEST: Retrieve metadata by entity_id and entity_type

        BUSINESS REQUIREMENT:
        Primary query pattern for fetching metadata for a specific entity

        VALIDATES:
        - Composite key lookup (entity_id + entity_type)
        - Correct metadata returned
        - None returned if not found
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        entity_id = uuid4()
        metadata = Metadata(
            entity_id=entity_id,
            entity_type='content',
            title='Test Content'
        )

        await dao.create(metadata, connection=db_transaction)

        # Execute: Retrieve by entity
        retrieved = await dao.get_by_entity(entity_id, 'content')

        # Verify: Correct metadata returned
        assert retrieved is not None
        assert retrieved.entity_id == entity_id
        assert retrieved.entity_type == 'content'

        # Verify: None returned for non-existent
        not_found = await dao.get_by_entity(uuid4(), 'course')
        assert not_found is None

    @pytest.mark.asyncio
    async def test_list_metadata_by_entity_type(self, db_transaction):
        """
        TEST: List all metadata for a given entity type

        BUSINESS REQUIREMENT:
        Browse all courses/content/users with pagination support

        VALIDATES:
        - Entity type filtering
        - Pagination with limit and offset
        - Results ordered by created_at DESC
        - Multiple records returned
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create multiple course metadata
        for i in range(5):
            metadata = Metadata(
                entity_id=uuid4(),
                entity_type='course',
                title=f'Course {i}'
            )
            await dao.create(metadata, connection=db_transaction)

        # Create some content metadata
        for i in range(3):
            metadata = Metadata(
                entity_id=uuid4(),
                entity_type='content',
                title=f'Content {i}'
            )
            await dao.create(metadata, connection=db_transaction)

        # Execute: List courses with pagination
        courses_page1 = await dao.list_by_entity_type('course', limit=3, offset=0)
        courses_page2 = await dao.list_by_entity_type('course', limit=3, offset=3)

        # Verify: Pagination works
        assert len(courses_page1) == 3
        assert len(courses_page2) == 2

        # Verify: Only courses returned
        for course in courses_page1:
            assert course.entity_type == 'course'


class TestMetadataDAOUpdate:
    """
    Test Suite: Metadata Update Operations

    BUSINESS REQUIREMENT:
    System must support metadata updates for content refinement,
    tag management, and metadata evolution over time.
    """

    @pytest.mark.asyncio
    async def test_update_metadata_fields(self, db_transaction):
        """
        TEST: Update metadata fields successfully

        BUSINESS REQUIREMENT:
        Metadata must be updatable to refine content descriptions,
        add tags, and improve search relevance.

        VALIDATES:
        - Metadata fields updated in database
        - updated_at timestamp refreshed
        - Search vector regenerated by trigger
        - Updated_by tracked
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        entity_id = uuid4()
        metadata = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='Original Title',
            tags=['original']
        )

        created = await dao.create(metadata, connection=db_transaction)
        original_updated_at = created.updated_at

        # Update metadata
        created.title = 'Updated Title'
        created.tags = ['updated', 'refreshed']
        created.description = 'New description added'
        created.updated_by = uuid4()

        # Execute: Update metadata
        updated = await dao.update(created, connection=db_transaction)

        # Verify: Fields updated
        assert updated.title == 'Updated Title'
        assert 'updated' in updated.tags
        assert updated.description == 'New description added'
        assert updated.updated_at > original_updated_at

    @pytest.mark.asyncio
    async def test_update_nonexistent_metadata_fails(self, db_transaction):
        """
        TEST: Updating non-existent metadata raises error

        BUSINESS REQUIREMENT:
        Update operations must validate metadata existence
        to prevent silent failures.

        VALIDATES:
        - MetadataNotFoundError raised
        - No database changes made
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create metadata with non-existent ID
        fake_metadata = Metadata(
            id=uuid4(),
            entity_id=uuid4(),
            entity_type='course',
            title='Non-existent'
        )

        with pytest.raises(MetadataNotFoundError) as exc_info:
            await dao.update(fake_metadata, connection=db_transaction)

        assert 'not found' in str(exc_info.value).lower()


class TestMetadataDAODelete:
    """
    Test Suite: Metadata Deletion Operations

    BUSINESS REQUIREMENT:
    System must support metadata deletion for content removal
    and data cleanup operations.
    """

    @pytest.mark.asyncio
    async def test_delete_metadata_success(self, db_transaction):
        """
        TEST: Delete metadata successfully

        BUSINESS REQUIREMENT:
        Metadata deletion enables content cleanup and removal

        VALIDATES:
        - Metadata deleted from database
        - Delete operation returns True
        - Subsequent retrieval returns None
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        entity_id = uuid4()
        metadata = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='To Delete'
        )

        created = await dao.create(metadata, connection=db_transaction)

        # Execute: Delete metadata
        deleted = await dao.delete(created.id)

        # Verify: Deletion successful
        assert deleted is True

        # Verify: Metadata no longer exists
        retrieved = await dao.get_by_id(created.id)
        assert retrieved is None

    @pytest.mark.asyncio
    async def test_delete_nonexistent_metadata_returns_false(self, db_transaction):
        """
        TEST: Deleting non-existent metadata returns False (idempotent)

        BUSINESS REQUIREMENT:
        Delete operations should be idempotent for robustness

        VALIDATES:
        - Returns False for non-existent ID
        - No error raised
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Execute: Delete non-existent metadata
        deleted = await dao.delete(uuid4())

        # Verify: Returns False
        assert deleted is False


class TestMetadataDAOFullTextSearch:
    """
    Test Suite: Full-Text Search Operations

    BUSINESS REQUIREMENT:
    System must provide full-text search with relevance ranking
    using PostgreSQL tsvector for intelligent content discovery.
    """

    @pytest.mark.asyncio
    async def test_search_metadata_by_title(self, db_transaction):
        """
        TEST: Full-text search finds metadata by title

        BUSINESS REQUIREMENT:
        Students and instructors must be able to search content
        by title for quick discovery.

        VALIDATES:
        - PostgreSQL full-text search with tsvector
        - Results ranked by relevance (ts_rank)
        - Multiple matches returned
        - Search across title, description, tags, keywords
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create test metadata
        python_course = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Python Programming Fundamentals',
            description='Learn Python from scratch'
        )
        await dao.create(python_course, connection=db_transaction)

        java_course = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Java Development Essentials',
            description='Master Java programming'
        )
        await dao.create(java_course, connection=db_transaction)

        # Execute: Search for "Python"
        results = await dao.search('Python')

        # Verify: Python course found
        assert len(results) > 0
        assert any('Python' in r.title for r in results)

    @pytest.mark.asyncio
    async def test_search_with_entity_type_filter(self, db_transaction):
        """
        TEST: Search with entity type filtering

        BUSINESS REQUIREMENT:
        Users should be able to filter search results by entity type
        (courses only, content only, etc.)

        VALIDATES:
        - Entity type filter applied correctly
        - Only matching types returned
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create course and content with "programming"
        course = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Programming Course'
        )
        await dao.create(course, connection=db_transaction)

        content = Metadata(
            entity_id=uuid4(),
            entity_type='content',
            title='Programming Tutorial Content'
        )
        await dao.create(content, connection=db_transaction)

        # Execute: Search courses only
        course_results = await dao.search('programming', entity_types=['course'])

        # Verify: Only courses returned
        assert len(course_results) > 0
        for result in course_results:
            assert result.entity_type == 'course'


class TestMetadataDAOFuzzySearch:
    """
    Test Suite: Fuzzy Search Operations (Typo Tolerance)

    BUSINESS REQUIREMENT:
    System must handle typos and partial matches using pg_trgm extension
    for user-friendly search experience with similarity scoring.
    """

    @pytest.mark.asyncio
    async def test_fuzzy_search_handles_typos(self, db_transaction):
        """
        TEST: Fuzzy search finds results despite typos

        BUSINESS REQUIREMENT:
        Students make typos when searching - system should still
        find relevant content using trigram similarity.

        VALIDATES:
        - pg_trgm similarity search
        - Typo tolerance: "Pythn" → "Python"
        - Similarity scores returned
        - Results ordered by similarity

        ALGORITHM:
        Uses PostgreSQL pg_trgm extension for trigram similarity
        matching with configurable threshold (0.0-1.0).
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create metadata
        metadata = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Python Programming Advanced',
            description='Advanced Python techniques'
        )
        await dao.create(metadata, connection=db_transaction)

        # Execute: Search with typo "Pythn"
        results = await dao.search_fuzzy(
            'Pythn',
            similarity_threshold=0.3,
            limit=10
        )

        # Verify: Results found despite typo
        assert len(results) > 0

        # Verify: Results are tuples of (Metadata, similarity_score)
        for metadata, score in results:
            assert isinstance(metadata, Metadata)
            assert isinstance(score, float)
            assert 0.0 <= score <= 1.0

    @pytest.mark.asyncio
    async def test_fuzzy_search_partial_matches(self, db_transaction):
        """
        TEST: Fuzzy search handles partial words

        BUSINESS REQUIREMENT:
        Users should find content with partial search terms

        VALIDATES:
        - Partial match: "prog" → "programming"
        - Similarity threshold enforcement

        EDGE CASE:
        Very short queries may return many low-quality matches
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        metadata = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Programming Fundamentals'
        )
        await dao.create(metadata, connection=db_transaction)

        # Execute: Partial search
        results = await dao.search_fuzzy('prog', similarity_threshold=0.3)

        # Verify: Programming course found
        assert len(results) > 0


class TestMetadataDAOTagQueries:
    """
    Test Suite: Tag-Based Query Operations

    BUSINESS REQUIREMENT:
    System must support tag-based content filtering using PostgreSQL
    array operators for precise content categorization and discovery.
    """

    @pytest.mark.asyncio
    async def test_get_metadata_by_tags(self, db_transaction):
        """
        TEST: Retrieve metadata by tags (AND logic)

        BUSINESS REQUIREMENT:
        Users should be able to filter content by multiple tags
        using AND logic (must have ALL tags).

        VALIDATES:
        - PostgreSQL array @> operator (contains all)
        - Case-insensitive tag matching
        - Multiple tags filtering

        ALGORITHM:
        Uses PostgreSQL array @> operator to find metadata that
        contains ALL specified tags (normalized to lowercase).
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create metadata with tags
        python_web = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Python Web Development',
            tags=['python', 'web', 'django']
        )
        await dao.create(python_web, connection=db_transaction)

        python_data = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Python Data Science',
            tags=['python', 'data', 'numpy']
        )
        await dao.create(python_data, connection=db_transaction)

        # Execute: Query by tags
        python_courses = await dao.get_by_tags(['python'])
        python_web_courses = await dao.get_by_tags(['python', 'web'])

        # Verify: Tag filtering works
        assert len(python_courses) >= 2
        assert len(python_web_courses) >= 1

        # Verify: All results have required tags
        for metadata in python_web_courses:
            assert 'python' in metadata.tags
            assert 'web' in metadata.tags

    @pytest.mark.asyncio
    async def test_tag_matching_case_insensitive(self, db_transaction):
        """
        TEST: Tag matching is case-insensitive

        BUSINESS REQUIREMENT:
        Tag searches should be case-insensitive for user convenience

        VALIDATES:
        - Tags normalized to lowercase
        - Query normalized to lowercase
        - "Python" matches "python"
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        metadata = Metadata(
            entity_id=uuid4(),
            entity_type='course',
            title='Test Course',
            tags=['Python', 'JavaScript']  # Mixed case
        )
        await dao.create(metadata, connection=db_transaction)

        # Execute: Query with lowercase
        results = await dao.get_by_tags(['python'])

        # Verify: Found despite case difference
        assert len(results) > 0


class TestMetadataDAOAnalyticsViews:
    """
    Test Suite: Analytics Materialized Views Operations

    BUSINESS REQUIREMENT:
    System must provide file upload/download analytics using
    materialized views for performance optimization.
    """

    @pytest.mark.asyncio
    async def test_get_upload_analytics_by_course(self, db_transaction):
        """
        TEST: Retrieve file upload analytics for a course

        BUSINESS REQUIREMENT:
        Instructors need visibility into file upload patterns
        to understand content creation activity.

        VALIDATES:
        - Materialized view query
        - Analytics aggregated by file type
        - Upload metrics: count, bytes, dates
        - User role tracking (instructor/student)
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        course_id = 12345

        # Execute: Get upload analytics
        analytics = await dao.get_upload_analytics_by_course(course_id)

        # Verify: Returns list (may be empty)
        assert isinstance(analytics, list)

        # If results exist, validate structure
        for record in analytics:
            assert 'course_id' in record
            assert 'file_type' in record
            assert 'total_uploads' in record

    @pytest.mark.asyncio
    async def test_get_download_analytics_by_course(self, db_transaction):
        """
        TEST: Retrieve file download analytics for a course

        BUSINESS REQUIREMENT:
        Instructors need to track which materials are being
        downloaded to assess content engagement.

        VALIDATES:
        - Download analytics from materialized view
        - Most downloaded file tracking
        - Download frequency by role
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        course_id = 12345

        # Execute: Get download analytics
        analytics = await dao.get_download_analytics_by_course(course_id)

        # Verify: Returns list
        assert isinstance(analytics, list)

    @pytest.mark.asyncio
    async def test_get_course_material_summary(self, db_transaction):
        """
        TEST: Get combined upload/download summary

        BUSINESS REQUIREMENT:
        Comprehensive view of material activity combining
        uploads and downloads for engagement analysis.

        VALIDATES:
        - Combined upload and download metrics
        - Downloads per upload ratio
        - Activity date ranges
        - User role statistics
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        course_id = 12345

        # Execute: Get material summary
        summary = await dao.get_course_material_summary(course_id)

        # Verify: Returns list
        assert isinstance(summary, list)

        # If results exist, validate engagement metric
        for record in summary:
            if 'downloads_per_upload' in record:
                assert isinstance(record['downloads_per_upload'], (int, float))


class TestMetadataDAOCourseMaterialSearch:
    """
    Test Suite: Course Material Search Operations

    BUSINESS REQUIREMENT:
    System must provide specialized search for course materials
    with ranking and filtering capabilities.
    """

    @pytest.mark.asyncio
    async def test_search_course_materials_with_filters(self, db_transaction):
        """
        TEST: Search course materials with entity type and course filters

        BUSINESS REQUIREMENT:
        Users need to search within specific courses and content types
        for targeted material discovery.

        VALIDATES:
        - Database function search_course_materials()
        - Entity type filtering
        - Course ID filtering
        - Relevance ranking
        - Headline generation
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Execute: Search with filters
        results = await dao.search_course_materials(
            search_query='programming',
            entity_type_filter='course',
            course_id_filter=None,
            limit_results=10
        )

        # Verify: Returns list
        assert isinstance(results, list)

    @pytest.mark.asyncio
    async def test_fuzzy_search_course_materials(self, db_transaction):
        """
        TEST: Fuzzy search for course materials

        BUSINESS REQUIREMENT:
        Course material search should handle typos and
        partial matches for better user experience.

        VALIDATES:
        - Database function fuzzy_search_course_materials()
        - Similarity threshold parameter
        - Similarity score in results
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Execute: Fuzzy search
        results = await dao.fuzzy_search_course_materials(
            search_text='pythn programing',
            similarity_threshold=0.3,
            limit_results=10
        )

        # Verify: Returns list
        assert isinstance(results, list)


class TestMetadataDAOEdgeCases:
    """
    Test Suite: Edge Cases and Error Handling

    BUSINESS REQUIREMENT:
    System must handle edge cases gracefully with proper
    error messages and data validation.
    """

    @pytest.mark.asyncio
    async def test_empty_search_query_returns_empty(self, db_transaction):
        """
        TEST: Empty search query returns no results

        BUSINESS REQUIREMENT:
        Search validation prevents invalid queries

        VALIDATES:
        - Empty query handling
        - No database errors
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Execute: Empty search
        results = await dao.search('', limit=10)

        # Verify: Empty results (or handles gracefully)
        assert isinstance(results, list)

    @pytest.mark.asyncio
    async def test_large_metadata_jsonb_storage(self, db_transaction):
        """
        TEST: Large JSONB metadata can be stored and retrieved

        BUSINESS REQUIREMENT:
        System must handle rich metadata without size limitations
        within PostgreSQL JSONB constraints.

        VALIDATES:
        - Large JSONB storage
        - Serialization/deserialization
        - No data corruption
        """
        dao = MetadataDAO(None)
        dao.pool = type('obj', (object,), {
            'acquire': lambda: type('ctx', (), {
                '__aenter__': lambda s: db_transaction,
                '__aexit__': lambda s, *args: None
            })()
        })()

        # Create large metadata
        large_metadata = {
            'topics': [f'Topic {i}' for i in range(100)],
            'sections': [
                {
                    'title': f'Section {i}',
                    'content': f'Content for section {i}' * 100
                } for i in range(50)
            ]
        }

        entity_id = uuid4()
        metadata = Metadata(
            entity_id=entity_id,
            entity_type='course',
            title='Large Metadata Course',
            metadata=large_metadata
        )

        # Execute: Create and retrieve
        created = await dao.create(metadata, connection=db_transaction)
        retrieved = await dao.get_by_id(created.id)

        # Verify: Large metadata preserved
        assert len(retrieved.metadata['topics']) == 100
        assert len(retrieved.metadata['sections']) == 50
