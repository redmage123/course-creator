# Local LLM Service Dependencies

# Web framework
fastapi>=0.109.0
uvicorn[standard]>=0.27.0
requests>=2.31.0

# Ollama client for local LLM inference
ollama>=0.1.7

# HTTP client for API requests
httpx>=0.27.0

# Async support
asyncio-throttle>=1.0.2

# Caching
cachetools>=5.3.2

# Testing
pytest>=7.4.3
pytest-asyncio>=0.21.1
pytest-cov>=4.1.0

# Logging
python-json-logger>=2.0.7

# Type hints
typing-extensions>=4.10.0

# Data validation
pydantic>=2.5.3
